# ‚ú® Projeto de demonstra√ß√£o - Tech Demo Showcase Pipeline de dados modular MLops‚ú®

[![MLOps](https://img.shields.io/badge/MLOps-Architecture-blueviolet?style=for-the-badge&logo=apacheairflow&logoColor=white)](https://ml-ops.org/)
[![Prefect](https://img.shields.io/badge/Orchestration-Prefect%202.x-8a00b6?style=for-the-badge&logo=prefect&logoColor=white)](https://www.prefect.io/)
[![MLflow](https://img.shields.io/badge/ML%20Platform-MLflow-blue?style=for-the-badge&logo=mlflow&logoColor=white)](https://mlflow.org/)
[![Python](https://img.shields.io/badge/Language-Python%203.11-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Microservices](https://img.shields.io/badge/Architecture-Microservices-purple?style=for-the-badge&logo=nginx&logoColor=white)](https://microservices.io/)
[![Data Pipeline](https://img.shields.io/badge/Pipeline-Data%20Driven-007ACC?style=for-the-badge&logo=apachekafka&logoColor=white)](https://en.wikipedia.org/wiki/Data_pipeline)

---

## üë®‚Äçüíª Sobre o Projeto: Construindo um Pipeline de MLOps para Previs√£o de Vendas com APIs, MLflow e Prefect

Ol√°! Sou **Elias Andrade**, um especialista em IA, Dados e MLOps, e este projeto √© uma demonstra√ß√£o pr√°tica e modular de como construo pipelines de Machine Learning de ponta a ponta, focado em **escalabilidade, desacoplamento e observabilidade**. Aqui, apresento uma **Prova de Conceito (POC)** de um sistema de previs√£o de vendas de ve√≠culos Chevrolet, simulando um ambiente de produ√ß√£o realista com princ√≠pios de **arquitetura de microservi√ßos** e orquestra√ß√£o robusta.

O objetivo principal √© demonstrar minha capacidade de projetar, implementar e gerenciar pipelines de ML que entregam valor de neg√≥cio cont√≠nuo, desde a ingest√£o de dados at√© o monitoramento do modelo em produ√ß√£o.

üîó [Conecte-se comigo no LinkedIn!](https://www.linkedin.com/in/itilmgf/)

---

## üéØ O Desafio: Prever Vendas em um Ecossistema Complexo

No cen√°rio atual, concession√°rias buscam otimizar estoque, campanhas de marketing e aloca√ß√£o de recursos. A previs√£o precisa de vendas √© crucial. No entanto, os dados podem vir de m√∫ltiplas fontes, precisar de pr√©-processamento complexo, e os modelos de ML exigem gerenciamento rigoroso, desde o treinamento at√© a implanta√ß√£o e monitoramento.

Este projeto aborda esses desafios atrav√©s de:
*   **Fontes de Dados Desacopladas:** Simula√ß√£o de APIs de dados.
*   **Inje√ß√£o de Dados Confi√°vel:** Orquestra√ß√£o para garantir a movimenta√ß√£o de dados.
*   **Centraliza√ß√£o de Dados:** Um "Data Lake" simplificado para consumo por pipelines.
*   **Pipeline de ML Completo:** Do pr√©-processamento √† avalia√ß√£o e registro do modelo.
*   **Servi√ßo de Modelo em Tempo Real:** Disponibiliza√ß√£o de previs√µes via API.
*   **Gerenciamento de Artefatos:** Armazenamento externo de relat√≥rios e gr√°ficos.
*   **Observabilidade:** Monitoramento do ciclo de vida do ML com MLflow e Prefect.

---

# Relat√≥rio de Teste da API de Modelo MLflow (2025-09-01 19:31:58)

Este relat√≥rio resume o teste de consumo da API de modelo MLflow para previs√£o de vendas Chevrolet.

## 1. Configura√ß√µes do Teste
- **URL da API de Modelo:** `http://127.0.0.1:8780/predict`
- **N√∫mero de Amostras Testadas:** `100`

## 2. Estat√≠sticas das Previs√µes
- **M√≠nimo de Vendas Previstas:** `3.40`
- **M√°ximo de Vendas Previstas:** `29.70`
- **M√©dia de Vendas Previstas:** `15.99`
- **Desvio Padr√£o das Vendas Previstas:** `6.01`

## 3. Amostra de Previs√µes
Aqui est√£o as primeiras 5 amostras de entrada com suas respectivas previs√µes:
| store_id   | model     |   month |   day_of_week |   predicted_sales |
|:-----------|:----------|--------:|--------------:|------------------:|
| Loja_09    | Montana   |      11 |             5 |             27.26 |
| Loja_20    | Equinox   |      10 |             4 |             18.02 |
| Loja_01    | Montana   |      12 |             0 |             24.46 |
| Loja_12    | Montana   |       3 |             5 |             21.32 |
| Loja_12    | Onix Plus |       3 |             6 |              6.58 |

## 4. Visualiza√ß√£o
Um gr√°fico da distribui√ß√£o das previs√µes e m√©dia por modelo foi gerado:
![Gr√°fico de Previs√µes](model_test_report_overview.png)

<img width="1200" height="600" alt="ml_model_predictions_plot" src="https://github.com/user-attachments/assets/f9ca790a-b2d7-4ca7-8c58-9495e599da10" />

---



## üöÄ Vis√£o Geral da Arquitetura: Microservi√ßos e Orquestra√ß√£o

Minha abordagem para este pipeline √© fundamentalmente baseada em **microservi√ßos**, onde cada componente executa uma fun√ß√£o espec√≠fica e se comunica via APIs bem definidas. Essa modularidade garante **flexibilidade**, **manutenibilidade** e **escalabilidade** independente de cada parte.
---

## ‚öôÔ∏è Detalhando os Componentes & Fluxo de Dados

Cada pe√ßa deste quebra-cabe√ßa foi cuidadosamente projetada para uma fun√ß√£o espec√≠fica, demonstrando um pipeline completo de MLOps.

### 1. üö∞ Fontes e Ingest√£o de Dados (APIs + Prefect)

A jornada dos dados come√ßa com a gera√ß√£o e ingest√£o:

*   **`src/api/data_generator/app.py` (API de Dados de Vendas - Porta 8777)**
    *   **Fun√ß√£o:** Simula a **fonte de dados prim√°ria** ‚Äì uma API RESTful que gera dados de vendas de ve√≠culos Chevrolet para 20 lojas ao longo de um ano. Inclui modelos populares, pre√ßos m√©dios e sazonalidade di√°ria/mensal, tornando os dados mais realistas.
    *   **Tecnologia:** Flask, Pandas, Numpy, Random.
    *   **Endpoint:** `/sales_data` (GET)
    *   **Minha Vis√£o:** Este √© um exemplo de uma fonte de dados *ativa*. No mundo real, poderia ser um CRM, ERP, ou um sistema de PDV, provendo dados brutos que precisam ser coletados.

*   **`src/flows/data_ingestion_flow.py` (Prefect Data Ingestion Flow)**
    *   **Fun√ß√£o:** O c√©rebro da orquestra√ß√£o de dados. Este **Prefect Flow** √© respons√°vel por buscar ativamente os dados brutos da `data_generator` e envi√°-los para a `data_lake` de forma confi√°vel. Utiliza **tasks** para cada etapa (fetch, push) e inclui tratamento de erros (`try-except`) para resili√™ncia.
    *   **Tecnologia:** Prefect 2.x, `requests`.
    *   **Minha Vis√£o:** Demonstra como orquestro a movimenta√ß√£o de dados. Prefect garante que o processo seja executado de forma agendada, monitorada, com retentativas e notifica√ß√£o de falhas, crucial para pipelines de dados de produ√ß√£o.

*   **`src/api/data_lake/app.py` (API de Data Lake - Porta 8778)**
    *   **Fun√ß√£o:** Atua como um **reposit√≥rio centralizado e passivo** para os dados ingeridos. Ele n√£o busca dados ativamente; apenas recebe (`POST /store_data`) e serve (`GET /datasource`) o que lhe √© enviado, armazenando-o em um banco de dados SQLite (`sales_data_lake.db`).
    *   **Tecnologia:** Flask, Pandas, SQLite.
    *   **Endpoints:** `/store_data` (POST), `/datasource` (GET).
    *   **Minha Vis√£o:** Este microservi√ßo simula a camada de ingest√£o para um "Data Lake" ou "Data Warehouse" simplificado. O desacoplamento aqui √© fundamental: a fonte de dados (data_generator) n√£o precisa saber onde os dados ser√£o armazenados, e os consumidores (ML Pipelines) s√≥ precisam saber de onde l√™-los.

### 2. üß† Pipeline de Machine Learning (MLflow)

Com os dados no Data Lake, entra em cena a magia do ML:

*   **`src/pipelines/model_training_pipeline.py` (MLflow Model Training Pipeline)**
    *   **Fun√ß√£o:** Este √© o cora√ß√£o do projeto. Um **pipeline completo de ML** que:
        1.  Busca os dados agregados da `data_lake`.
        2.  Realiza **pr√©-processamento avan√ßado**: engenharia de features (m√™s, dia da semana), One-Hot Encoding para categ√≥ricas, e cria um `ColumnTransformer` robusto.
        3.  Treina um modelo de **Deep Learning (TensorFlow/Keras)** para prever as vendas.
        4.  **Avalia** o modelo usando m√©tricas como MAE, MSE, RMSE e R2 Score.
        5.  Realiza uma **predi√ß√£o de "Top Car"** para um m√™s espec√≠fico, demonstrando o valor de neg√≥cio imediato.
        6.  Gera **relat√≥rios detalhados (Markdown)** e **gr√°ficos (PNG)** do desempenho do modelo e das previs√µes.
        7.  **Rastreia todo o experimento com MLflow**: Registra par√¢metros, m√©tricas, artefatos (pr√©-processador, modelo Keras), e o **modelo completo no MLflow Model Registry** como um `pyfunc` customizado, que encapsula tanto o pr√©-processador quanto o modelo TensorFlow.
        8.  Faz o **upload dos relat√≥rios e gr√°ficos** para a `artifact_store` externa, garantindo a acessibilidade.
    *   **Tecnologia:** MLflow, TensorFlow/Keras, Scikit-learn, Pandas, Matplotlib, `requests`.
    *   **Minha Vis√£o:** Este pipeline √© um claro exemplo de **MLOps em a√ß√£o**. Desde o rastreamento de experimentos com MLflow at√© a modulariza√ß√£o do pr√©-processamento e a encapsula√ß√£o do modelo (Pyfunc), tudo visa reprodutibilidade, governan√ßa e deploy facilitado. O upload para a `artifact_store` ilustra o desacoplamento do MLflow para fins de distribui√ß√£o e arquivamento de relat√≥rios.

*   **`src/pipelines/data_analysis_pipeline.py` (MLflow Data Analysis Pipeline)**
    *   **Fun√ß√£o:** Um pipeline auxiliar focado na **an√°lise explorat√≥ria de dados (EDA)** e gera√ß√£o de insights. Ele busca os dados do `data_lake`, identifica e visualiza os **10 modelos mais vendidos**.
    *   **Tecnologia:** MLflow, Pandas, Matplotlib, `requests`.
    *   **Minha Vis√£o:** Destaca a import√¢ncia da fase de explora√ß√£o de dados no ciclo de vida do ML, al√©m de demonstrar a capacidade de gerar e persistir relat√≥rios visuais como artefatos valiosos, tanto no MLflow quanto externamente na `artifact_store`.

### 3. üì¶ Armazenamento de Artefatos e Model Serving

A persist√™ncia e o consumo das sa√≠das s√£o cruciais:

*   **`src/api/artifact_store/app.py` (API de Storage de Artefatos - Porta 8779)**
    *   **Fun√ß√£o:** Um microservi√ßo simples para **armazenamento gen√©rico de arquivos (artefatos)**. Ele recebe uploads (`POST /upload_artifact`) e serve arquivos (`GET /artifacts/<filename>`).
    *   **Tecnologia:** Flask, `werkzeug.utils` (para nomes de arquivos seguros).
    *   **Endpoints:** `/upload_artifact` (POST), `/artifacts/<filename>` (GET), `/list_artifacts` (GET).
    *   **Minha Vis√£o:** Este servi√ßo atua como um "S3 local" para relat√≥rios, gr√°ficos, e outros artefatos que n√£o s√£o necessariamente gerenciados pelo MLflow, mas que precisam ser persistidos e acess√≠veis. Ele ilustra a flexibilidade de desacoplar o armazenamento de artefatos n√£o-MLflow do pr√≥prio MLflow Tracking Server.

*   **`src/api/model_serving/app.py` (API de Servi√ßo de Modelo - Porta 8780)**
    *   **Fun√ß√£o:** A interface para o consumo do modelo de ML em produ√ß√£o. Carrega o modelo treinado e registrado no **MLflow Model Registry** (`ChevroletSalesPredictor:latest`) e exp√µe um endpoint de `predict` em tempo real. Garante que os dados de entrada correspondam √† `ModelSignature` definida.
    *   **Tecnologia:** MLflow, Flask, Pandas, Numpy.
    *   **Endpoints:** `/predict` (POST), `/model_status` (GET).
    *   **Minha Vis√£o:** Demonstra o deploy de modelos de ML como **microservi√ßos desacoplados**. A API de serving √© agn√≥stica ao pipeline de treinamento, buscando a "√∫ltima vers√£o" do modelo no Registry, o que facilita rollouts e rollbacks. A valida√ß√£o de schema √© uma pr√°tica de MLOps crucial para garantir a integridade das previs√µes.

*   **`scripts/run_model_tester.py` (MLflow Model Tester)**
    *   **Fun√ß√£o:** Um script de **valida√ß√£o p√≥s-deploy** essencial para MLOps. Ele gera dados sint√©ticos, envia-os para a `model_serving` API, coleta as previs√µes e gera um relat√≥rio de teste (Markdown) e um gr√°fico de distribui√ß√£o das previs√µes.
    *   **Tecnologia:** `requests`, Pandas, Matplotlib.
    *   **Minha Vis√£o:** Destaca a import√¢ncia de testar e validar modelos continuamente ap√≥s a implanta√ß√£o, garantindo que a API de serving esteja funcional e o modelo entregando previs√µes dentro do esperado.

### 4. üõ†Ô∏è Orquestra√ß√£o de Infraestrutura (Scripts Utilit√°rios)

Para gerenciar o ambiente de desenvolvimento e produ√ß√£o:

*   **`scripts/start_mlflow_server.py`:** Inicia o MLflow Tracking Server e UI (`http://127.0.0.1:5001`), usando `data/mlflow_backend.db` para metadados e `mlruns/` para artefatos. Essencial para rastreamento e registro de modelos.
*   **`scripts/start_prefect_server.py`:** Inicia o Prefect Server e UI (`http://localhost:4200`), a plataforma de orquestra√ß√£o de fluxos de dados.
*   **`scripts/run_all_servers.py`:** Um script de conveni√™ncia para iniciar *todas* as APIs e servidores (MLflow, Prefect, Data Generator, Data Lake, Artifact Store, Model Serving) em terminais separados, simplificando a configura√ß√£o do ambiente.

---

## üìä Fluxo de Dados de Ponta a Ponta: Uma Jornada do Dado

1.  **Gera√ß√£o/Coleta de Dados Brutos (API de Gera√ß√£o de Dados)**: Dados simulados de vendas s√£o criados.
2.  **Inje√ß√£o Orquestrada (Prefect Data Ingestion Flow)**: O Prefect busca os dados da API de Gera√ß√£o e os envia para a API de Data Lake.
3.  **Armazenamento no Data Lake (API de Data Lake)**: Os dados s√£o persistidos no `sales_data_lake.db`, servindo como fonte de verdade.
4.  **An√°lise e Visualiza√ß√£o (MLflow Data Analysis Pipeline)**: O pipeline de an√°lise l√™ do Data Lake, calcula top modelos e gera gr√°ficos que s√£o logados no MLflow e enviados para a API de Storage de Artefatos.
5.  **Treinamento e Registro do Modelo (MLflow Model Training Pipeline)**:
    *   L√™ dados do Data Lake.
    *   Pr√©-processa (engenharia de features, One-Hot Encoding).
    *   Treina um modelo TensorFlow/Keras.
    *   Avalia o modelo.
    *   Gera relat√≥rios e gr√°ficos do desempenho.
    *   **Loga tudo no MLflow Tracking Server**.
    *   **Registra o modelo (junto com seu pr√©-processador)** no MLflow Model Registry, com `ModelSignature` e ambiente Conda.
    *   Envia relat√≥rios e gr√°ficos para a API de Storage de Artefatos.
6.  **Servi√ßo de Modelo (API de Servi√ßo de Modelo)**: A API de Serving carrega a "vers√£o mais recente" do modelo do MLflow Model Registry, tornando-o dispon√≠vel para infer√™ncia em tempo real.
7.  **Valida√ß√£o P√≥s-Deploy (MLflow Model Tester)**: O tester gera dados sint√©ticos, testa a API de Serving e gera relat√≥rios de valida√ß√£o para garantir a integridade do servi√ßo.
8.  **Monitoramento e Governan√ßas (MLflow UI & Prefect UI)**: Todas as execu√ß√µes de pipelines, par√¢metros, m√©tricas, artefatos e modelos s√£o vis√≠veis e gerenci√°veis via MLflow UI. A orquestra√ß√£o e o status dos fluxos s√£o monitorados via Prefect UI.

---

## üõ†Ô∏è Tecnologias Principais Utilizadas

Este projeto demonstra profici√™ncia com as seguintes ferramentas e frameworks:

*   **Python 3.11:** Linguagem de programa√ß√£o principal.
*   **Flask:** Framework para constru√ß√£o de APIs RESTful.
*   **Prefect 2.x:** Plataforma de orquestra√ß√£o de dataflows e workflows, com UI para monitoramento.
*   **MLflow:** Plataforma para o ciclo de vida de Machine Learning (Tracking, Models, Registry, Projects, Serving).
*   **TensorFlow/Keras:** Framework de Deep Learning para constru√ß√£o e treinamento do modelo de previs√£o.
*   **Scikit-learn:** Ferramentas para pr√©-processamento de dados e avalia√ß√£o de modelos.
*   **Pandas:** Biblioteca para manipula√ß√£o e an√°lise de dados.
*   **Numpy:** Biblioteca para computa√ß√£o num√©rica.
*   **Matplotlib:** Para gera√ß√£o de visualiza√ß√µes de dados e relat√≥rios.
*   **Requests:** Para comunica√ß√£o HTTP entre os microservi√ßos.
*   **SQLite:** Banco de dados leve para persist√™ncia de dados local.
*   **`subprocess` & `os`:** Para gerenciamento de processos e sistema de arquivos.

---

## üåç Aplica√ß√µes no Mundo Real e Valor de Neg√≥cio

Este pipeline modular e desacoplado n√£o √© apenas uma demonstra√ß√£o t√©cnica; ele reflete a forma como solu√ß√µes de IA/ML s√£o constru√≠das e mantidas em ambientes de produ√ß√£o. As aplica√ß√µes e o valor de neg√≥cio s√£o vastos:

*   **Previs√£o de Demanda e Vendas:** Otimiza√ß√£o de estoque, planejamento de produ√ß√£o, aloca√ß√£o de equipes de vendas.
*   **Marketing Otimizado:** Identifica√ß√£o de tend√™ncias de modelos para campanhas direcionadas.
*   **Detec√ß√£o de Anomalias:** Adapta√ß√£o do pipeline para identificar padr√µes incomuns em dados financeiros, de seguran√ßa, etc.
*   **Sistemas de Recomenda√ß√£o:** Com ajustes, o mesmo padr√£o de ingest√£o e serving pode ser usado para sistemas que recomendam produtos ou servi√ßos.
*   **Manuten√ß√£o Preditiva:** Prever falhas de equipamentos com base em dados de sensores.

Minha experi√™ncia em arquitetar e implementar tal infraestrutura significa que posso traduzir requisitos de neg√≥cio em solu√ß√µes de ML escal√°veis, robustas e de alto impacto.

---

## üöÄ Como Come√ßar (Setup & Execu√ß√£o)

Para explorar este projeto, siga estas etapas. Garanto uma experi√™ncia suave e um ambiente de trabalho bem organizado!

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone https://github.com/SeuUsuario/mlops-sales-prediction.git
    cd mlops-sales-prediction
    ```
2.  **Crie e Ative um Ambiente Virtual:**
    ```bash
    python -m venv .venv
    # No Linux/macOS
    source .venv/bin/activate
    # No Windows
    .venv\Scripts\activate
    ```
3.  **Instale as Depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    # Para garantir que todas as depend√™ncias estejam fixadas:
    pip freeze > requirements.txt
    ```
4.  **Execute o Script de Refatora√ß√£o (Apenas na primeira vez ou se a estrutura estiver bagun√ßada):**
    Caso voc√™ tenha a estrutura antiga ou queira reconfirmar a organiza√ß√£o, execute:
    ```bash
    python refactor_project.py
    ```
    Este script organizar√° todos os arquivos na estrutura MLOps profissional.
5.  **Inicie Todos os Servi√ßos (APIs e Servidores):**
    Abra um terminal na raiz do projeto e execute:
    ```bash
    python scripts/run_all_servers.py
    ```
    Isso abrir√° v√°rias janelas de terminal, cada uma executando um servi√ßo (MLflow UI, Prefect UI, APIs de dados/modelos). Deixe-as rodando.

6.  **Execute os Pipelines de Dados e ML (em NOVOS terminais):**
    Com os servi√ßos base rodando, abra *novos terminais* na raiz do projeto (e ative seu ambiente virtual em cada um).

    *   **1. Ingest√£o de Dados (Prefect Flow):**
        ```bash
        python src/flows/data_ingestion_flow.py
        ```
        (Isso enviar√° dados da API de Gera√ß√£o para a API de Data Lake)

    *   **2. An√°lise de Dados (MLflow Pipeline):**
        ```bash
        python src/pipelines/data_analysis_pipeline.py
        ```
        (Isso gerar√° um relat√≥rio de top modelos)

    *   **3. Treinamento e Registro do Modelo (MLflow Pipeline):**
        ```bash
        python src/pipelines/model_training_pipeline.py
        ```
        (Isso treinar√°, registrar√° o modelo MLflow, e gerar√° relat√≥rios)

    *   **4. Teste de Modelo P√≥s-Deploy:**
        ```bash
        python scripts/run_model_tester.py
        ```
        (Isso testar√° a API de Modelo e gerar√° um relat√≥rio de teste)

7.  **Explore as UIs:**
    *   **MLflow UI:** `http://127.0.0.1:5001` (para ver experimentos, modelos, artefatos)
    *   **Prefect UI:** `http://localhost:4200` (para ver o status e logs dos flows)
    *   **APIs:** Verifique as p√°ginas iniciais das APIs (ex: `http://127.0.0.1:8777`, `8778`, `8779`, `8780`)

---

## üìà Melhorias Futuras e Roadmap

*   **CI/CD Automatizado:** Implementar GitHub Actions (ou Jenkins, GitLab CI) para automa√ß√£o de testes, build, deploy de servi√ßos e triggers de pipelines de ML.
*   **Monitoramento de Drift de Dados e Modelo:** Integra√ß√£o com ferramentas como Evidently AI ou Fiddler para detectar quando a performance do modelo se degrada ou os dados de entrada mudam.
*   **Infraestrutura Cloud-Native:** Migrar os servi√ßos para plataformas como AWS (ECS/EKS, S3, RDS, SageMaker), GCP (Cloud Run, GCS, Vertex AI) ou Azure (Container Apps, Blob Storage, Azure ML).
*   **Modelos Mais Complexos:** Experimentar com modelos de s√©ries temporais ou ensemble para previs√µes mais avan√ßadas.
*   **UI/Dashboard para Previs√µes:** Construir uma interface de usu√°rio simples (Streamlit, Dash) para consumir a API de servi√ßo de modelo e visualizar previs√µes.
*   **A/B Testing de Modelos:** Implementar estrat√©gias para testar novas vers√µes de modelos em produ√ß√£o.
*   **Seguran√ßa e Autentica√ß√£o:** Adicionar autentica√ß√£o e autoriza√ß√£o para as APIs.

---

## ü§ù Contato e Colabora√ß√£o

Sou apaixonado por construir solu√ß√µes de IA robustas e escal√°veis. Se voc√™ tem um projeto desafiador ou quer discutir as melhores pr√°ticas de MLOps, adoraria conectar!

**Elias Andrade**  
[LinkedIn: https://www.linkedin.com/in/itilmgf/](https://www.linkedin.com/in/itilmgf/)  
[GitHub: https://github.com/SeuUsuario](https://github.com/SeuUsuario) <!-- Substitua 'SeuUsuario' pelo seu real username do GitHub -->

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

---
